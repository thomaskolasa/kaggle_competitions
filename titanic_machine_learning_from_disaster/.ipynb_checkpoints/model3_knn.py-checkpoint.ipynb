{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# For a random forest classifier to work, I need to first impute missing values and convert categorical variables to labels\n",
    "\n",
    "##### Processing Training Data #####\n",
    "\n",
    "# male and female\n",
    "train_df['sex_boolean'] = train_df.Sex.map({'male':0, 'female':1})\n",
    "train_df = train_df.drop('Sex', axis=1)\n",
    "\n",
    "# age\n",
    "median_train_age = train_df.Age.median()\n",
    "train_df['Age'] = train_df['Age'].fillna(median_train_age)\n",
    "\n",
    "# Ticket\n",
    "train_df = train_df.drop('Ticket', axis=1)\n",
    "\n",
    "# Cabin\n",
    "train_df['cabin_boolean'] = 0\n",
    "train_df.Cabin = train_df.Cabin.fillna(0)\n",
    "train_df.loc[train_df['Cabin'] != 0,'cabin_boolean'] = 1\n",
    "train_df = train_df.drop('Cabin', axis=1)\n",
    "\n",
    "# Port of Embarkation\n",
    "train_df['Embarked'] = train_df.Embarked.fillna('S')\n",
    "embarked_dummies = pd.get_dummies(train_df.Embarked, prefix = 'embarked')\n",
    "train_df = pd.concat([train_df, embarked_dummies], axis=1)\n",
    "train_df = train_df.drop(['Embarked', 'Name'], axis=1)\n",
    "\n",
    "##### Processing Testing Data #####\n",
    "\n",
    "# male and female\n",
    "test_df['sex_boolean'] = test_df.Sex.map({'male':0, 'female':1})\n",
    "test_df = test_df.drop('Sex', axis=1)\n",
    "\n",
    "# Age\n",
    "median_test_age = test_df.Age.median()\n",
    "test_df['Age'] = test_df['Age'].fillna(median_test_age)\n",
    "\n",
    "# Tickets\n",
    "test_df = test_df.drop('Ticket', axis=1)\n",
    "\n",
    "# Fare\n",
    "test_df.Fare = test_df.Fare.fillna(test_df.Fare[test_df.Pclass == 3].median())\n",
    "\n",
    "# Cabin\n",
    "test_df['cabin_boolean'] = 0\n",
    "test_df.Cabin = test_df.Cabin.fillna(0)\n",
    "test_df.loc[test_df['Cabin'] != 0,'cabin_boolean'] = 1\n",
    "test_df = test_df.drop('Cabin', axis=1)\n",
    "\n",
    "# Embarked\n",
    "embarked_dummies = pd.get_dummies(test_df.Embarked, prefix = 'embarked')\n",
    "test_df = pd.concat([test_df, embarked_dummies], axis=1)\n",
    "test_df = test_df.drop(['Embarked', 'Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_df.drop('Survived', axis=1),train_df.Survived,\n",
    "                                                    test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A heuristic is to set k equal to the square root of the number of observations. Let's see what happens when we set it to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = round((len(train_df) + len(test_df))**.5)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=36, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=36, weights='uniform')\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6685393258426966"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68715083798882681"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since those scores are only based on one specific train/test split, finding the mean of 10 random splits would likely hold more water..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65587357478202557"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, x_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63137254901960793"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, x_test, y_test, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How likely is it that the best k is the square root of the number of obsevations? I'll try a slew of k's to see which one has the best accuracy. I can also try a different weighting metric. While by default, sklearn's knn classifier gives equal weight to all nearest neighbors to an observation, it can also weigh neighbors proportionally to the inverse of their distances to an observation. Let's see which performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for weight in ['uniform', 'distance']:\n",
    "    for k in xrange(1, 100):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights=weight)\n",
    "        knn.fit(x_train, y_train)\n",
    "        results.append([weight, k, cross_val_score(knn, x_train, y_train, cv=10).mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['uniform', 34, 0.66146825396825404],\n",
       " ['uniform', 35, 0.65873071763916835],\n",
       " ['uniform', 38, 0.65861167002012078],\n",
       " ['uniform', 29, 0.6573021462105969],\n",
       " ['uniform', 33, 0.65728314330427018],\n",
       " ['uniform', 32, 0.65728258439526044],\n",
       " ['uniform', 22, 0.6572635814889336],\n",
       " ['uniform', 37, 0.65724290185557788],\n",
       " ['uniform', 36, 0.65587357478202557],\n",
       " ['uniform', 41, 0.65581433042700643],\n",
       " ['uniform', 27, 0.65450480661748267],\n",
       " ['uniform', 40, 0.65442544153811755],\n",
       " ['uniform', 31, 0.65309691482226695],\n",
       " ['uniform', 28, 0.65305667337357465],\n",
       " ['uniform', 45, 0.65299742901855584],\n",
       " ['uniform', 39, 0.65299742901855562],\n",
       " ['distance', 32, 0.65168846411804171],\n",
       " ['distance', 43, 0.65168734630002234],\n",
       " ['uniform', 42, 0.6515688575899844],\n",
       " ['uniform', 19, 0.65033869885982576]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key = lambda x: x[2], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best cross validated k-nearest neighbor results on the training set came from uniform weighting and 34 neighbors. I will use these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=34, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=34, weights='uniform')\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66146825396825404"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, x_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63692810457516347"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, x_test, y_test, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at 34 nearest neighbors seems to do slightly better than 36 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkolasa/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from IPython.kernel.zmq import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "submission = test_df[['PassengerId']]\n",
    "submission['Survived'] = knn.predict(test_df)\n",
    "\n",
    "submission.to_csv('submissions/model3_knn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN correctly predicts 0.64115 of the test set on Kaggle. This is not as good as the random forest classifier, but maybe a more nuanced instance-based method will perform better. Stay tuned for some support vector machine models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
